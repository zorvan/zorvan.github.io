<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description"
    content="Time-Series Analysis پیشبینی سری زمانی Predicting Chaotic Time-Series Using Neural Networks in Clojure.
 پیشبینی سری های زمانی آشوبناک توسط شبکه های عصبی
 Quantitative Research on Quality of Consciousness">
  <title> Time-Series Analysis پیشبینی سری زمانی - Narrative Consciousness </title>

  <!-- stylesheets -->
  <link media="all" href="http://netdna.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css" rel="stylesheet">
  <link media="all" href="http://netdna.bootstrapcdn.com/font-awesome/4.2.0/css/font-awesome.min.css" rel="stylesheet">
  <link media="all" rel="stylesheet" href="/assets/css/site.css">
  <link media="all" rel="stylesheet" href="/assets/css/syntax.css">
  

</head>


<body>
  <header>
  <nav class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container-fluid">
      <div class="navbar-header">
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a id="site-title" class="navbar-brand" href="/">
          <img class="pull-left img-responsive" src="/images/logo/logo.png"> 
          <span class="name-holder">Narrative Consciousness</span>
        </a>
      </div>

      <div class="collapse navbar-collapse" id="navbar">

        <ul id="main-menu" class="nav navbar-nav navbar-right">

          
            <li><a href="/">
              <i class="fa fa-home"></i> Home</a>
            </li>
          
            <li><a href="/surf/">
              <i class="fa fa-compass"></i> Surf</a>
            </li>
          
            <li><a href="/art/">
              <i class="fa fa-camera"></i> Art</a>
            </li>
          
            <li><a href="/about/">
              <i class="fa fa-info-circle"></i> About Me</a>
            </li>
          

        </ul>
      </div>
      <!-- /.navbar-collapse -->
    </div>
    <!-- /.container-fluid -->
  </nav>

</header>

  
  <script type="text/javascript"
    src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

<div class="container">
  <div class="row">
    <div class="col-xs-12 col-sm-12 col-md-offset-1 col-md-10 col-lg-offset-2 col-lg-8">
      <div class="page">

        <header class="page-header">
          <h3 class="page-title"><a href="/2015/11/21/Time-Series-Prediction-NN.html">Time-Series Analysis پیشبینی سری زمانی</a></h3>
          <div class="post-metadata">
            <div> <i class="fa fa-calendar"></i>
              <time>
                Saturday, November 21, 2015
              </time>
            </div>
            <div> <i class="fa fa-tag"></i>
                
                  <span class="label label-tag">ML</span>
                
                  <span class="label label-tag">Neural-Networks</span>
                
                  <span class="label label-tag">Clojure</span>
                
            </div>
          </div>

        </header>

        <article class="page-content">
          <p>Predicting Chaotic Time-Series Using Neural Networks in Clojure.
<div align="right"> پیشبینی سری های زمانی آشوبناک توسط شبکه های عصبی</div></p>

<!--more-->

<figure class="highlight"><pre><code class="language-clojure" data-lang="clojure">   <span class="c1">; Written by Amin Razavi , Dec 2015</span>
<span class="c1">; Amirkabir University of Technology (Tehran Polytechnic)</span>

<span class="p">(</span><span class="kd">ns </span><span class="nv">SimpleNN.core</span>
  <span class="p">(</span><span class="ss">:require</span> <span class="p">[</span><span class="nv">clojure.core.matrix</span> <span class="ss">:refer</span> <span class="ss">:all</span><span class="p">]</span>
            <span class="p">[</span><span class="nv">clojure.core.matrix.operators</span> <span class="ss">:refer</span> <span class="ss">:all</span><span class="p">]))</span>

<span class="p">(</span><span class="k">def </span><span class="nv">activation-fn</span>
  <span class="s">&quot;defines the function implemented by a neuron&quot;</span>
  <span class="p">(</span><span class="k">fn </span><span class="p">[</span><span class="nv">x</span><span class="p">]</span> <span class="p">(</span><span class="nf">Math/tanh</span> <span class="nv">x</span><span class="p">)))</span>
<span class="p">(</span><span class="k">def </span><span class="nv">dactivation-fn</span>
  <span class="s">&quot;derivative of activation function&quot;</span>
  <span class="p">(</span><span class="k">fn </span><span class="p">[</span><span class="nv">y</span><span class="p">]</span> <span class="p">(</span><span class="nb">- </span><span class="mf">1.0</span> <span class="p">(</span><span class="nb">* </span><span class="nv">y</span> <span class="nv">y</span><span class="p">))))</span>

<span class="p">(</span><span class="k">def </span><span class="nv">range2</span>
  <span class="s">&quot;returns range with interval 2&quot;</span>
  <span class="o">#</span><span class="p">(</span><span class="nb">take </span><span class="p">(</span><span class="nb">- </span><span class="nv">%2</span> <span class="nv">%1</span><span class="p">)</span> <span class="p">(</span><span class="nb">iterate </span><span class="p">(</span><span class="nb">partial + </span><span class="mi">2</span><span class="p">)</span> <span class="nv">%1</span><span class="p">)))</span>

<span class="p">(</span><span class="kd">defn </span><span class="nv">get-weights</span> <span class="p">[</span><span class="nv">network</span><span class="p">]</span>
  <span class="s">&quot;returns the weights of a network&quot;</span>
  <span class="p">(</span><span class="nb">map first </span><span class="p">(</span><span class="nf">partition</span> <span class="mi">1</span> <span class="mi">2</span> <span class="p">(</span><span class="nb">rest </span><span class="nv">network</span><span class="p">))))</span>

<span class="p">(</span><span class="kd">defn </span><span class="nv">get-layers</span> <span class="p">[</span><span class="nv">network</span><span class="p">]</span>
  <span class="s">&quot;returns the layers of a network, including input and output&quot;</span>
  <span class="p">(</span><span class="nb">map first </span><span class="p">(</span><span class="nf">partition</span> <span class="mi">1</span> <span class="mi">2</span> <span class="nv">network</span><span class="p">)))</span>

<span class="p">(</span><span class="kd">defn </span><span class="nv">layer-activation</span> <span class="p">[</span><span class="nv">inputs</span> <span class="nv">strengths</span><span class="p">]</span>
   <span class="s">&quot;forward propagate the input of a layer&quot;</span>
   <span class="p">(</span><span class="nf">mapv</span> <span class="nv">activation-fn</span>
         <span class="p">(</span><span class="nf">mapv</span> <span class="o">#</span><span class="p">(</span><span class="nb">reduce + </span><span class="nv">%</span><span class="p">)</span>
               <span class="p">(</span><span class="nb">* </span><span class="nv">inputs</span> <span class="p">(</span><span class="nf">transpose</span> <span class="nv">strengths</span><span class="p">)))))</span>

<span class="p">(</span><span class="kd">defn </span><span class="nv">output-deltas</span> <span class="p">[</span><span class="nv">targets</span> <span class="nv">outputs</span><span class="p">]</span>
  <span class="s">&quot;measures the delta errors for the output layer (Desired value – actual value) and multiplying it by the gradient of the activation function&quot;</span>
  <span class="p">(</span><span class="nb">* </span><span class="p">(</span><span class="nf">mapv</span> <span class="nv">dactivation-fn</span> <span class="nv">outputs</span><span class="p">)</span>
     <span class="p">(</span><span class="nb">- </span><span class="nv">targets</span> <span class="nv">outputs</span><span class="p">)))</span>

<span class="p">(</span><span class="kd">defn </span><span class="nv">hlayer-deltas</span> <span class="p">[</span><span class="nv">deltas</span> <span class="p">[</span><span class="nv">neurons</span> <span class="nv">strengths</span><span class="p">]]</span>
  <span class="s">&quot;measures the delta errors for the hidden layer based on the output deltas&quot;</span>
  <span class="p">(</span><span class="nb">* </span><span class="p">(</span><span class="nf">mapv</span> <span class="nv">dactivation-fn</span> <span class="nv">neurons</span><span class="p">)</span>
     <span class="p">(</span><span class="nf">mapv</span> <span class="o">#</span><span class="p">(</span><span class="nb">reduce + </span><span class="nv">%</span><span class="p">)</span>
           <span class="p">(</span><span class="nb">* </span><span class="nv">deltas</span> <span class="nv">strengths</span><span class="p">))))</span>

<span class="p">(</span><span class="kd">defn </span><span class="nv">update-strengths</span> <span class="p">[[</span><span class="nv">deltas</span> <span class="nv">neurons</span> <span class="nv">strengths</span> <span class="nv">lrate</span><span class="p">]]</span>
  <span class="s">&quot;update the strengths based on the deltas and the learning rate&quot;</span>
  <span class="p">(</span><span class="nb">+ </span><span class="nv">strengths</span> <span class="p">(</span><span class="nb">* </span><span class="nv">lrate</span>
                  <span class="p">(</span><span class="nf">mapv</span> <span class="o">#</span><span class="p">(</span><span class="nb">* </span><span class="nv">deltas</span> <span class="nv">%</span><span class="p">)</span> <span class="nv">neurons</span><span class="p">))))</span>

<span class="p">(</span><span class="kd">defn </span><span class="nv">feed-forward</span> <span class="p">[</span><span class="nv">input</span> <span class="nv">network</span><span class="p">]</span>
  <span class="s">&quot;feeds input through the network to the output&quot;</span>
  <span class="p">(</span><span class="k">let </span><span class="p">[</span><span class="nv">strenghts</span> <span class="p">(</span><span class="nf">get-weights</span> <span class="nv">network</span><span class="p">)</span> <span class="c1">;get weight vectors between input, hidden levels and output</span>
        <span class="nv">new-activations</span> <span class="p">(</span><span class="nf">reductions</span> <span class="nv">layer-activation</span> <span class="nv">input</span> <span class="nv">strenghts</span><span class="p">)</span> <span class="c1">;get the new level activations given the inputs</span>
        <span class="nv">activations-indexes</span> <span class="p">(</span><span class="nb">cons </span><span class="mi">0</span> <span class="p">(</span><span class="nb">map </span><span class="p">(</span><span class="nb">partial + </span><span class="mi">2</span><span class="p">)</span> <span class="p">(</span><span class="nf">range2</span> <span class="mi">0</span> <span class="p">(</span><span class="nb">count </span><span class="nv">strenghts</span><span class="p">))))]</span> <span class="c1">;get the indexes corresponding to the position of level activations in network</span>
    <span class="p">(</span><span class="nb">apply </span><span class="p">(</span><span class="nb">partial assoc </span><span class="nv">network</span><span class="p">)</span> <span class="c1">; replace values at indexes with replacement values</span>
           <span class="p">(</span><span class="nb">interleave </span><span class="nv">activations-indexes</span> <span class="nv">new-activations</span><span class="p">))))</span> <span class="c1">; associate positions with replacement values</span>

<span class="p">(</span><span class="kd">defn </span><span class="nv">update-weights</span> <span class="p">[</span><span class="nv">network</span> <span class="nv">target</span> <span class="nv">learning-rate</span><span class="p">]</span>
  <span class="s">&quot;updates the weights based on targets and learning rate with back-prop&quot;</span>
  <span class="p">(</span><span class="k">let </span><span class="p">[</span><span class="nv">strenghts</span> <span class="p">(</span><span class="nb">reverse </span><span class="p">(</span><span class="nf">get-weights</span> <span class="nv">network</span><span class="p">))</span> <span class="c1">;get weight vectors between input, hidden levels and output</span>
        <span class="nv">layers</span> <span class="p">(</span><span class="nb">reverse </span><span class="p">(</span><span class="nf">get-layers</span> <span class="nv">network</span><span class="p">))</span> <span class="c1">;get layers values</span>
        <span class="nv">o-deltas</span> <span class="p">(</span><span class="nf">output-deltas</span> <span class="nv">target</span> <span class="p">(</span><span class="nb">first </span><span class="nv">layers</span><span class="p">))</span> <span class="c1">;use the output layer</span>
        <span class="nv">h-deltas</span> <span class="p">(</span><span class="nf">-&gt;&gt;</span> <span class="c1">;compute the deltas for the hidden layers starting from the output deltas (include the init value: o-deltas)</span>
                  <span class="p">(</span><span class="nb">mapcat </span><span class="o">#</span><span class="p">(</span><span class="nb">list </span><span class="p">[</span><span class="nv">%1</span> <span class="nv">%2</span><span class="p">])</span> <span class="p">(</span><span class="nb">rest </span><span class="nv">layers</span><span class="p">)</span> <span class="nv">strenghts</span><span class="p">)</span> <span class="c1">;list of vectors containing a hidden layer and the weights to the next layer</span>
                  <span class="p">(</span><span class="nb">butlast </span>,<span class="p">)</span>           <span class="c1">;ignore the input layer</span>
                  <span class="p">(</span><span class="nf">reductions</span> <span class="nv">hlayer-deltas</span> <span class="nv">o-deltas</span> ,<span class="p">)</span> <span class="c1">;produce the deltas for the hidden layers</span>
                  <span class="p">)</span>
        <span class="nv">h-deltas-layer-weights</span> <span class="p">(</span><span class="nb">mapcat </span><span class="o">#</span><span class="p">(</span><span class="nb">list </span><span class="p">[</span><span class="nv">%1</span> <span class="nv">%2</span> <span class="nv">%3</span> <span class="nv">learning-rate</span><span class="p">])</span> <span class="nv">h-deltas</span> <span class="p">(</span><span class="nb">rest </span><span class="nv">layers</span><span class="p">)</span> <span class="nv">strenghts</span><span class="p">)</span> <span class="c1">;collect values from the three parameter vectors in a single list of vectors</span>
        <span class="nv">n-strenghts</span> <span class="p">(</span><span class="nb">map </span><span class="nv">update-strengths</span> <span class="nv">h-deltas-layer-weights</span><span class="p">)</span> <span class="c1">;produce the new strenghts</span>
        <span class="nv">strenghts-indexes</span> <span class="p">(</span><span class="nb">reverse </span><span class="p">(</span><span class="nb">map inc </span><span class="p">(</span><span class="nf">range2</span> <span class="mi">0</span> <span class="p">(</span><span class="nb">count </span><span class="nv">strenghts</span><span class="p">))))]</span> <span class="c1">;get the indexes corresponding to the position of weights in network</span>
    <span class="p">(</span><span class="nb">apply </span><span class="p">(</span><span class="nb">partial assoc </span><span class="nv">network</span><span class="p">)</span> <span class="c1">; replace values at indexes with replacement values</span>
           <span class="p">(</span><span class="nb">interleave </span><span class="nv">strenghts-indexes</span> <span class="nv">n-strenghts</span><span class="p">))))</span> <span class="c1">; associate positions with replacement values</span>

<span class="p">(</span><span class="kd">defn </span><span class="nv">train-network</span> <span class="p">[</span><span class="nv">network</span> <span class="nv">input</span> <span class="nv">target</span> <span class="nv">learning-rate</span><span class="p">]</span>
  <span class="s">&quot;train network with one set of target data&quot;</span>
  <span class="p">(</span><span class="nf">update-weights</span> <span class="p">(</span><span class="nf">feed-forward</span> <span class="nv">input</span> <span class="nv">network</span><span class="p">)</span> <span class="nv">target</span> <span class="nv">learning-rate</span><span class="p">))</span>

<span class="p">(</span><span class="kd">defn </span><span class="nv">train-data</span> <span class="p">[</span><span class="nv">network</span> <span class="nv">data</span> <span class="nv">learning-rate</span><span class="p">]</span>
  <span class="s">&quot;train network with a set of data in the form of [[input1 target1] [input2 target2]]&quot;</span>
  <span class="p">(</span><span class="nb">if-let </span><span class="p">[[</span><span class="nv">input</span> <span class="nv">target</span><span class="p">]</span> <span class="p">(</span><span class="nb">first </span><span class="nv">data</span><span class="p">)]</span>
    <span class="p">(</span><span class="nf">recur</span>
     <span class="p">(</span><span class="nf">train-network</span> <span class="nv">network</span> <span class="nv">input</span> <span class="nv">target</span> <span class="nv">learning-rate</span><span class="p">)</span>
     <span class="p">(</span><span class="nb">rest </span><span class="nv">data</span><span class="p">)</span>
     <span class="nv">learning-rate</span><span class="p">)</span>
    <span class="nv">network</span><span class="p">))</span>

<span class="p">(</span><span class="kd">defn </span><span class="nv">train-epochs</span> <span class="p">[</span><span class="nv">n</span> <span class="nv">network</span> <span class="nv">training-data</span> <span class="nv">learning-rate</span><span class="p">]</span>
  <span class="s">&quot;train repeatedly n times over the same tranining data in the form of [[input1 target1] [input2 target2]]  &quot;</span>
  <span class="p">(</span><span class="k">if </span><span class="p">(</span><span class="nb">zero? </span><span class="nv">n</span><span class="p">)</span>
    <span class="nv">network</span>
    <span class="p">(</span><span class="nf">recur</span> <span class="p">(</span><span class="nb">dec </span><span class="nv">n</span><span class="p">)</span>
           <span class="p">(</span><span class="nf">train-data</span> <span class="nv">network</span> <span class="nv">training-data</span> <span class="nv">learning-rate</span><span class="p">)</span>
           <span class="nv">training-data</span>
           <span class="nv">learning-rate</span><span class="p">)))</span>

<span class="p">(</span><span class="kd">defn </span><span class="nv">ff</span> <span class="p">[</span><span class="nv">input</span> <span class="nv">network</span><span class="p">]</span>
  <span class="s">&quot;Feed forward and return output neurons&quot;</span>
  <span class="p">(</span><span class="nb">last </span><span class="p">(</span><span class="nf">feed-forward</span> <span class="nv">input</span> <span class="nv">network</span><span class="p">)))</span>

<span class="p">(</span><span class="kd">defn </span><span class="nv">gen-strengths</span> <span class="p">[</span><span class="nv">to</span> <span class="nv">from</span><span class="p">]</span>
  <span class="s">&quot;generate random strengths for layer&quot;</span>
  <span class="p">(</span><span class="k">let </span><span class="p">[</span><span class="nv">l</span> <span class="p">(</span><span class="nb">* </span><span class="nv">to</span> <span class="nv">from</span><span class="p">)]</span>
    <span class="p">(</span><span class="nb">map </span><span class="nv">vec</span> <span class="p">(</span><span class="nf">partition</span> <span class="nv">from</span> <span class="p">(</span><span class="nf">repeatedly</span> <span class="nv">l</span> <span class="o">#</span><span class="p">(</span><span class="nb">rand </span><span class="p">(</span><span class="nb">/ </span><span class="mi">1</span> <span class="nv">l</span><span class="p">)))))))</span>

<span class="p">(</span><span class="kd">defn </span><span class="nv">construct-network</span>
  <span class="p">([</span><span class="nv">num-in</span> <span class="nv">num-hidden</span> <span class="nv">num-out</span><span class="p">]</span>
  <span class="s">&quot;construct a three layer neural network&quot;</span>
  <span class="p">(</span><span class="nf">construct-network</span> <span class="nv">num-in</span> <span class="nv">num-hidden</span> <span class="mi">0</span> <span class="nv">num-out</span><span class="p">))</span>
  <span class="p">([</span><span class="nv">size-in</span> <span class="nv">size-hidden</span> <span class="nv">num-hidden</span> <span class="nv">size-out</span><span class="p">]</span>
  <span class="s">&quot;construct a N layer neural network&quot;</span>
  <span class="p">(</span><span class="nf">vec</span> <span class="p">(</span><span class="nb">map </span><span class="nv">vec</span> <span class="p">(</span><span class="nf">concat</span>
                 <span class="p">[(</span><span class="nb">repeat </span><span class="nv">size-in</span> <span class="mi">0</span><span class="p">)</span>
                  <span class="p">(</span><span class="nf">gen-strengths</span> <span class="nv">size-in</span> <span class="nv">size-hidden</span><span class="p">)</span>
                  <span class="p">(</span><span class="nb">repeat </span><span class="nv">size-hidden</span> <span class="mi">0</span><span class="p">)]</span>
                 <span class="p">(</span><span class="nf">-&gt;&gt;</span>
                  <span class="p">(</span><span class="nb">cons </span><span class="p">(</span><span class="nf">gen-strengths</span> <span class="nv">size-hidden</span> <span class="nv">size-hidden</span><span class="p">)</span> <span class="p">[(</span><span class="nb">repeat </span><span class="nv">size-hidden</span> <span class="mi">0</span><span class="p">)])</span>
                  <span class="p">(</span><span class="nb">repeat </span><span class="p">(</span><span class="nb">dec </span><span class="nv">num-hidden</span><span class="p">))</span>
                  <span class="p">(</span><span class="nb">apply </span><span class="nv">concat</span><span class="p">))</span>
                 <span class="p">[(</span><span class="nf">gen-strengths</span> <span class="nv">size-hidden</span> <span class="nv">size-out</span><span class="p">)</span>
                  <span class="p">(</span><span class="nb">repeat </span><span class="nv">size-out</span> <span class="mi">0</span><span class="p">)])))))</span>

<span class="c1">;;-----------------------------------------</span>
<span class="c1">;; Application</span>
<span class="c1">;;-----------------------------------------</span>
<span class="p">(</span><span class="k">def </span><span class="nv">Lambda</span> <span class="mf">-3.544</span><span class="p">)</span><span class="c1">; try values between [3.54409,3.56995]</span>
<span class="p">(</span><span class="k">def </span><span class="nv">Window</span> <span class="mi">10</span><span class="p">)</span>
<span class="p">(</span><span class="k">def </span><span class="nv">Overlap</span> <span class="mi">1</span><span class="p">)</span>
<span class="p">(</span><span class="k">def </span><span class="nv">Length</span> <span class="mi">120</span><span class="p">)</span>
<span class="p">(</span><span class="k">def </span><span class="nv">Test</span> <span class="mi">10</span><span class="p">)</span>
<span class="p">(</span><span class="k">def </span><span class="nv">Epochs</span> <span class="mi">120</span><span class="p">)</span>

<span class="c1">; Chaos : Logistic</span>
<span class="p">(</span><span class="kd">defn </span><span class="nv">logistic</span> <span class="p">[</span><span class="nv">x</span><span class="p">]</span>
    <span class="p">(</span><span class="nb">* </span><span class="nv">Lambda</span> <span class="nv">x</span> <span class="p">(</span><span class="nb">dec </span><span class="nv">x</span><span class="p">)))</span>

<span class="p">(</span><span class="kd">defn </span><span class="nv">Pair-IO</span> <span class="p">[</span><span class="nv">v</span> <span class="nv">W</span><span class="p">]</span>
  <span class="p">[(</span><span class="nf">vec</span> <span class="p">(</span><span class="nb">take </span><span class="nv">W</span> <span class="nv">v</span><span class="p">))</span> <span class="p">[(</span><span class="nb">last </span><span class="nv">v</span><span class="p">)]])</span>

<span class="p">(</span><span class="kd">defn </span><span class="nv">Provide-Data</span> <span class="p">[</span><span class="nv">ts</span> <span class="nv">W</span> <span class="nv">O</span><span class="p">]</span>
  <span class="p">(</span><span class="nf">vec</span> <span class="p">(</span><span class="nb">map </span><span class="o">#</span><span class="p">(</span><span class="nf">Pair-IO</span> <span class="nv">%</span> <span class="p">(</span><span class="nb">dec </span><span class="nv">W</span><span class="p">))</span> <span class="p">(</span><span class="nf">partition</span> <span class="nv">W</span> <span class="nv">O</span> <span class="nv">ts</span><span class="p">))))</span>

<span class="p">(</span><span class="k">def </span><span class="nv">ts</span> <span class="p">(</span><span class="nb">iterate </span><span class="nv">logistic</span> <span class="p">(</span><span class="nf">rand</span><span class="p">)))</span> <span class="c1">; 1000 samples of chaotic time series.</span>
<span class="p">(</span><span class="k">def </span><span class="nv">training-data</span> <span class="p">(</span><span class="nf">Provide-Data</span> <span class="p">(</span><span class="nb">take </span><span class="nv">Length</span> <span class="nv">ts</span><span class="p">)</span> <span class="nv">Window</span> <span class="nv">Overlap</span><span class="p">))</span> <span class="c1">; Partition time-series with sliding window of length 10 and 9 overlaps. </span>
<span class="p">(</span><span class="k">def </span><span class="nv">test-data</span> <span class="p">(</span><span class="nf">Provide-Data</span> <span class="p">(</span><span class="nb">take </span><span class="nv">Test</span> <span class="p">(</span><span class="nb">drop </span><span class="nv">Length</span> <span class="nv">ts</span><span class="p">))</span> <span class="nv">Window</span> <span class="nv">Overlap</span><span class="p">))</span> 

<span class="p">(</span><span class="k">def </span><span class="nv">ts-nn</span> <span class="p">(</span><span class="nf">construct-network</span>  <span class="p">(</span><span class="nb">dec </span><span class="nv">Window</span><span class="p">)</span> <span class="mi">10</span> <span class="mi">2</span> <span class="mi">1</span><span class="p">))</span> <span class="c1">; 10 input , 2 hidden layer of size 10 , 1 output</span>

<span class="p">(</span><span class="k">def </span><span class="nv">trained-nc</span> <span class="p">(</span><span class="nf">train-epochs</span> <span class="nv">Epochs</span> <span class="nv">ts-nn</span> <span class="nv">training-data</span> <span class="mf">0.2</span><span class="p">))</span>
<span class="c1">;; after training</span>
<span class="p">(</span><span class="nf">ff</span>  <span class="p">(</span><span class="nb">first </span><span class="p">(</span><span class="nb">nth </span><span class="nv">test-data</span> <span class="mi">0</span><span class="p">))</span> <span class="nv">trained-nc</span><span class="p">)</span>
<span class="p">(</span><span class="nb">second </span><span class="p">(</span><span class="nb">nth </span><span class="nv">test-data</span> <span class="mi">0</span><span class="p">))</span></code></pre></figure>

        </article>
      </div>
    </div>
  </div>
</div>


  

<footer class="footer">
    <div class="container">
      <div class="row">
        <div class="col-lg-offset-3 col-lg-6">
            <div class="row">
              <div class="col-xs-12 text-center">
                <small>&copy; Ritamin, 2015</small>
              </div>
            </div>
        </div>
      </div>
    </div>
  </footer>

  <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script>
  <script src="http://netdna.bootstrapcdn.com/bootstrap/3.2.0/js/bootstrap.min.js"></script>
  <!--<script src="/assets/js/prism.js"></script> -->
  <script src="/assets/js/site.js"></script>

</body>

</html>
